\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{krizhevsky2012imagenet}
\citation{krizhevsky2009learning}
\citation{guo2017calibration}
\citation{dietterich2000ensemble}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:introduction}{{1}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Motivation}{1}{subsection.1.1}\protected@file@percent }
\citation{shafer1976mathematical}
\citation{xu1992methods}
\citation{liu2024deep}
\citation{dietterich2000ensemble}
\citation{breiman1996bagging}
\citation{freund1997decision}
\citation{wolpert1992stacked}
\citation{lakshminarayanan2017simple}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Proposed Solution}{2}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Contributions}{2}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Key Findings}{2}{subsection.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Paper Organization}{2}{subsection.1.5}\protected@file@percent }
\citation{gal2016dropout,kendall2017uncertainties}
\citation{mackay1992practical}
\citation{gal2016dropout}
\citation{lakshminarayanan2017simple}
\citation{sensoy2018evidential}
\citation{shafer1976mathematical,dempster1968generalization}
\citation{xu1992methods}
\citation{basir2007engine}
\citation{kiani2017medical}
\citation{le2002application}
\citation{arxiv2024feature}
\citation{sensoy2018evidential}
\citation{liu2024deep}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{3}{section.2}\protected@file@percent }
\newlabel{sec:related}{{2}{3}{Related Work}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Ensemble Learning}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Uncertainty Quantification in Deep Learning}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Dempster-Shafer Theory}{3}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}DS Theory in Machine Learning}{3}{subsection.2.4}\protected@file@percent }
\citation{smets1994transferable}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{4}{section.3}\protected@file@percent }
\newlabel{sec:methodology}{{3}{4}{Methodology}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Framework Overview}{4}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Belief Assignment from Neural Networks}{4}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Dempster's Rule of Combination}{4}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Uncertainty Metrics}{4}{subsection.3.4}\protected@file@percent }
\citation{krizhevsky2009learning}
\citation{he2016deep}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Overview of our DS-based ensemble fusion framework. Individual CNN models generate softmax predictions, which are converted to belief mass functions. These masses are combined using Dempster's rule to produce a fused prediction with explicit uncertainty quantification including belief, plausibility, and conflict measures.}}{5}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:framework}{{1}{5}{Overview of our DS-based ensemble fusion framework. Individual CNN models generate softmax predictions, which are converted to belief mass functions. These masses are combined using Dempster's rule to produce a fused prediction with explicit uncertainty quantification including belief, plausibility, and conflict measures}{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Decision Making}{5}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Adaptive Weighting}{5}{subsection.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Experimental Setup}{5}{section.4}\protected@file@percent }
\newlabel{sec:experiments}{{4}{5}{Experimental Setup}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Dataset}{5}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Model Architectures}{5}{subsection.4.2}\protected@file@percent }
\citation{simonyan2014very}
\citation{sandler2018mobilenetv2}
\citation{huang2017densely}
\citation{guo2017calibration}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Baseline Methods}{6}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Evaluation Metrics}{6}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Implementation Details}{6}{subsection.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Ablation Studies}{6}{subsection.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Results and Analysis}{6}{section.5}\protected@file@percent }
\newlabel{sec:results}{{5}{6}{Results and Analysis}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Overall Performance}{6}{subsection.5.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Classification Accuracy on CIFAR-10 Test Set}}{7}{table.caption.3}\protected@file@percent }
\newlabel{tab:main_results}{{1}{7}{Classification Accuracy on CIFAR-10 Test Set}{table.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Visual Comparison of Methods}{7}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Uncertainty Quantification Analysis}{7}{subsection.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Accuracy comparison across individual models, traditional ensemble methods, and DS-based fusion. DS fusion (rightmost coral bar) achieves the highest accuracy while also providing uncertainty metrics unavailable to other methods.}}{7}{figure.caption.4}\protected@file@percent }
\newlabel{fig:comparison}{{2}{7}{Accuracy comparison across individual models, traditional ensemble methods, and DS-based fusion. DS fusion (rightmost coral bar) achieves the highest accuracy while also providing uncertainty metrics unavailable to other methods}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}DS Fusion Process Visualization}{7}{subsection.5.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Comprehensive uncertainty analysis from DS fusion: (a) Belief-plausibility intervals for 100 sample predictions showing uncertainty ranges, (b) Distribution of conflict measures across all test samples, (c) Box plot comparing conflict between correct and incorrect predictions, (d) Distribution of uncertainty interval widths. The analysis demonstrates that DS fusion provides meaningful uncertainty quantification, with clear differences between confident and uncertain predictions.}}{8}{figure.caption.5}\protected@file@percent }
\newlabel{fig:uncertainty}{{3}{8}{Comprehensive uncertainty analysis from DS fusion: (a) Belief-plausibility intervals for 100 sample predictions showing uncertainty ranges, (b) Distribution of conflict measures across all test samples, (c) Box plot comparing conflict between correct and incorrect predictions, (d) Distribution of uncertainty interval widths. The analysis demonstrates that DS fusion provides meaningful uncertainty quantification, with clear differences between confident and uncertain predictions}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Calibration Quality}{8}{subsection.5.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Visualization of the DS fusion process: (a) Softmax predictions from three individual models showing different confidence levels and some disagreement, (b) Fused prediction after applying Dempster's rule, demonstrating how conflicting evidence is resolved, (c) Uncertainty metrics for the predicted class, including belief, plausibility, interval width, and conflict. The example shows how DS fusion synthesizes diverse evidence while quantifying uncertainty.}}{9}{figure.caption.6}\protected@file@percent }
\newlabel{fig:fusion_process}{{4}{9}{Visualization of the DS fusion process: (a) Softmax predictions from three individual models showing different confidence levels and some disagreement, (b) Fused prediction after applying Dempster's rule, demonstrating how conflicting evidence is resolved, (c) Uncertainty metrics for the predicted class, including belief, plausibility, interval width, and conflict. The example shows how DS fusion synthesizes diverse evidence while quantifying uncertainty}{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Calibration reliability diagrams comparing (a) traditional simple averaging which tends to be overconfident, and (b) DS fusion which achieves better calibration. The diagonal dashed line represents perfect calibration. Smaller gaps between predicted confidence and actual accuracy indicate better calibration. DS fusion reduces calibration error by explicitly modeling uncertainty.}}{9}{figure.caption.7}\protected@file@percent }
\newlabel{fig:calibration}{{5}{9}{Calibration reliability diagrams comparing (a) traditional simple averaging which tends to be overconfident, and (b) DS fusion which achieves better calibration. The diagonal dashed line represents perfect calibration. Smaller gaps between predicted confidence and actual accuracy indicate better calibration. DS fusion reduces calibration error by explicitly modeling uncertainty}{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Ablation Studies}{9}{subsection.5.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7}Conflict Analysis}{9}{subsection.5.7}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Conflict Measure Analysis}}{9}{table.caption.9}\protected@file@percent }
\newlabel{tab:conflict}{{2}{9}{Conflict Measure Analysis}{table.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Ablation study results: (a) Effect of ensemble size showing performance gains up to 5 models with diminishing returns, (b) Impact of temperature parameter with optimal range 1.0-1.5, (c) Comparison of belief assignment strategies with direct assignment performing best, (d) Importance of model diversity with heterogeneous architectures significantly outperforming homogeneous ensembles.}}{10}{figure.caption.8}\protected@file@percent }
\newlabel{fig:ablation}{{6}{10}{Ablation study results: (a) Effect of ensemble size showing performance gains up to 5 models with diminishing returns, (b) Impact of temperature parameter with optimal range 1.0-1.5, (c) Comparison of belief assignment strategies with direct assignment performing best, (d) Importance of model diversity with heterogeneous architectures significantly outperforming homogeneous ensembles}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.8}Confusion Matrix Analysis}{10}{subsection.5.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.9}Computational Efficiency}{10}{subsection.5.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Confusion matrices comparing (a) simple average ensemble and (b) DS fusion ensemble on CIFAR-10 test set. Darker colors on the diagonal indicate higher accuracy. DS fusion shows improved diagonal dominance, particularly for challenging classes like cat, dog, and bird, demonstrating better discrimination between visually similar categories.}}{11}{figure.caption.10}\protected@file@percent }
\newlabel{fig:confusion}{{7}{11}{Confusion matrices comparing (a) simple average ensemble and (b) DS fusion ensemble on CIFAR-10 test set. Darker colors on the diagonal indicate higher accuracy. DS fusion shows improved diagonal dominance, particularly for challenging classes like cat, dog, and bird, demonstrating better discrimination between visually similar categories}{figure.caption.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Computational Cost Comparison (per sample)}}{11}{table.caption.11}\protected@file@percent }
\newlabel{tab:computational}{{3}{11}{Computational Cost Comparison (per sample)}{table.caption.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion}{11}{section.6}\protected@file@percent }
\newlabel{sec:discussion}{{6}{11}{Discussion}{section.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Summary of Key Findings}{11}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Theoretical and Practical Advantages}{11}{subsection.6.2}\protected@file@percent }
\citation{arxiv2024feature}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Implications for Safety-Critical Applications}{12}{subsection.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Insights from Ablation Studies}{12}{subsection.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Comparison with Recent Work}{12}{subsection.6.5}\protected@file@percent }
\citation{sensoy2018evidential}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}Limitations and Future Directions}{13}{subsection.6.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7}Practical Recommendations}{13}{subsection.6.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{14}{section.7}\protected@file@percent }
\newlabel{sec:conclusion}{{7}{14}{Conclusion}{section.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Main Contributions Revisited}{14}{subsection.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Broader Impact}{14}{subsection.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Future Research Directions}{14}{subsection.7.3}\protected@file@percent }
\bibstyle{plain}
\bibdata{references}
\bibcite{arxiv2024feature}{1}
\bibcite{basir2007engine}{2}
\bibcite{breiman1996bagging}{3}
\bibcite{dempster1968generalization}{4}
\bibcite{dietterich2000ensemble}{5}
\bibcite{freund1997decision}{6}
\bibcite{gal2016dropout}{7}
\bibcite{guo2017calibration}{8}
\bibcite{he2016deep}{9}
\bibcite{huang2017densely}{10}
\bibcite{kendall2017uncertainties}{11}
\bibcite{kiani2017medical}{12}
\bibcite{krizhevsky2009learning}{13}
\bibcite{krizhevsky2012imagenet}{14}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Concluding Remarks}{15}{subsection.7.4}\protected@file@percent }
\bibcite{lakshminarayanan2017simple}{15}
\bibcite{le2002application}{16}
\bibcite{liu2024deep}{17}
\bibcite{mackay1992practical}{18}
\bibcite{sandler2018mobilenetv2}{19}
\bibcite{sensoy2018evidential}{20}
\bibcite{shafer1976mathematical}{21}
\bibcite{simonyan2014very}{22}
\bibcite{smets1994transferable}{23}
\bibcite{wolpert1992stacked}{24}
\bibcite{xu1992methods}{25}
\gdef \@abspage@last{16}

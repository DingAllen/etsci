\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{krizhevsky2012imagenet}
\citation{krizhevsky2009learning}
\citation{dietterich2000ensemble}
\citation{shafer1976mathematical}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:introduction}{{1}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}The Need for Principled Uncertainty Quantification}{1}{subsection.1.1}\protected@file@percent }
\citation{xu1992methods}
\citation{liu2024deep}
\citation{dietterich2000ensemble}
\citation{breiman1996bagging}
\citation{freund1997decision}
\citation{wolpert1992stacked}
\citation{lakshminarayanan2017simple}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Our Approach and Contributions}{2}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Why This Matters}{2}{subsection.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Paper Organization}{2}{subsection.1.4}\protected@file@percent }
\citation{gal2016dropout,kendall2017uncertainties}
\citation{mackay1992practical}
\citation{gal2016dropout}
\citation{lakshminarayanan2017simple}
\citation{sensoy2018evidential}
\citation{shafer1976mathematical,dempster1968generalization}
\citation{xu1992methods}
\citation{basir2007engine}
\citation{kiani2017medical}
\citation{le2002application}
\citation{arxiv2024feature}
\citation{sensoy2018evidential}
\citation{liu2024deep}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{3}{section.2}\protected@file@percent }
\newlabel{sec:related}{{2}{3}{Related Work}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Ensemble Learning}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Uncertainty Quantification in Deep Learning}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Dempster-Shafer Theory}{3}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}DS Theory in Machine Learning}{3}{subsection.2.4}\protected@file@percent }
\citation{sensoy2018evidential}
\citation{guo2017calibration}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{4}{section.3}\protected@file@percent }
\newlabel{sec:methodology}{{3}{4}{Methodology}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Framework Overview}{4}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}From Softmax Probabilities to Basic Belief Assignments}{4}{subsection.3.2}\protected@file@percent }
\newlabel{eq:direct}{{1}{4}{From Softmax Probabilities to Basic Belief Assignments}{equation.3.1}{}}
\newlabel{eq:temperature}{{3}{4}{From Softmax Probabilities to Basic Belief Assignments}{equation.3.3}{}}
\newlabel{eq:calibrated}{{4}{4}{From Softmax Probabilities to Basic Belief Assignments}{equation.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Dempster's Rule of Combination}{4}{subsection.3.3}\protected@file@percent }
\newlabel{eq:dempster}{{5}{4}{Dempster's Rule of Combination}{equation.3.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Overview of our DS-based ensemble fusion framework. Individual CNN models generate softmax predictions, which are converted to belief mass functions. These masses are combined using Dempster's rule to produce a fused prediction with explicit uncertainty quantification including belief, plausibility, and conflict measures.}}{5}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:framework}{{1}{5}{Overview of our DS-based ensemble fusion framework. Individual CNN models generate softmax predictions, which are converted to belief mass functions. These masses are combined using Dempster's rule to produce a fused prediction with explicit uncertainty quantification including belief, plausibility, and conflict measures}{figure.caption.2}{}}
\newlabel{eq:conflict}{{6}{5}{Dempster's Rule of Combination}{equation.3.6}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Conflict-Aware Decision Policy}}{5}{algorithm.1}\protected@file@percent }
\citation{smets1994transferable}
\citation{krizhevsky2009learning}
\citation{he2016deep}
\citation{simonyan2014very}
\citation{sandler2018mobilenetv2}
\citation{huang2017densely}
\citation{gal2016dropout}
\citation{lakshminarayanan2017simple}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Uncertainty Quantification: Epistemic vs. Aleatoric}{6}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Decision Making and Uncertainty Reporting}{6}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Reliability-Based Weighting}{6}{subsection.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Experimental Setup}{6}{section.4}\protected@file@percent }
\newlabel{sec:experiments}{{4}{6}{Experimental Setup}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Dataset and Training}{6}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Baseline Comparisons}{6}{subsection.4.2}\protected@file@percent }
\citation{guo2017calibration}
\citation{hendrycks2016baseline}
\citation{goodfellow2014explaining}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Evaluation Metrics}{7}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Implementation Details}{7}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Ablation Studies}{7}{subsection.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Results and Analysis}{7}{section.5}\protected@file@percent }
\newlabel{sec:results}{{5}{7}{Results and Analysis}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Overall Performance}{7}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Visual Comparison of Methods}{7}{subsection.5.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Classification Accuracy on CIFAR-10 Test Set}}{8}{table.caption.3}\protected@file@percent }
\newlabel{tab:main_results}{{1}{8}{Classification Accuracy on CIFAR-10 Test Set}{table.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Uncertainty Quantification Analysis}{8}{subsection.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Accuracy comparison across individual models, traditional ensemble methods, and DS-based fusion. DS fusion (rightmost coral bar) achieves the highest accuracy while also providing uncertainty metrics unavailable to other methods.}}{8}{figure.caption.4}\protected@file@percent }
\newlabel{fig:comparison}{{2}{8}{Accuracy comparison across individual models, traditional ensemble methods, and DS-based fusion. DS fusion (rightmost coral bar) achieves the highest accuracy while also providing uncertainty metrics unavailable to other methods}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}DS Fusion Process Visualization}{8}{subsection.5.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Comprehensive uncertainty analysis from DS fusion: (a) Belief-plausibility intervals for 100 sample predictions showing uncertainty ranges, (b) Distribution of conflict measures across all test samples, (c) Box plot comparing conflict between correct and incorrect predictions, (d) Distribution of uncertainty interval widths. The analysis demonstrates that DS fusion provides meaningful uncertainty quantification, with clear differences between confident and uncertain predictions.}}{9}{figure.caption.5}\protected@file@percent }
\newlabel{fig:uncertainty}{{3}{9}{Comprehensive uncertainty analysis from DS fusion: (a) Belief-plausibility intervals for 100 sample predictions showing uncertainty ranges, (b) Distribution of conflict measures across all test samples, (c) Box plot comparing conflict between correct and incorrect predictions, (d) Distribution of uncertainty interval widths. The analysis demonstrates that DS fusion provides meaningful uncertainty quantification, with clear differences between confident and uncertain predictions}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Calibration Quality}{9}{subsection.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Ablation Studies}{9}{subsection.5.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Visualization of the DS fusion process: (a) Softmax predictions from three individual models showing different confidence levels and some disagreement, (b) Fused prediction after applying Dempster's rule, demonstrating how conflicting evidence is resolved, (c) Uncertainty metrics for the predicted class, including belief, plausibility, interval width, and conflict. The example shows how DS fusion synthesizes diverse evidence while quantifying uncertainty.}}{10}{figure.caption.6}\protected@file@percent }
\newlabel{fig:fusion_process}{{4}{10}{Visualization of the DS fusion process: (a) Softmax predictions from three individual models showing different confidence levels and some disagreement, (b) Fused prediction after applying Dempster's rule, demonstrating how conflicting evidence is resolved, (c) Uncertainty metrics for the predicted class, including belief, plausibility, interval width, and conflict. The example shows how DS fusion synthesizes diverse evidence while quantifying uncertainty}{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Calibration reliability diagrams comparing (a) traditional simple averaging which tends to be overconfident, and (b) DS fusion which achieves better calibration. The diagonal dashed line represents perfect calibration. Smaller gaps between predicted confidence and actual accuracy indicate better calibration. DS fusion reduces calibration error by explicitly modeling uncertainty.}}{10}{figure.caption.7}\protected@file@percent }
\newlabel{fig:calibration}{{5}{10}{Calibration reliability diagrams comparing (a) traditional simple averaging which tends to be overconfident, and (b) DS fusion which achieves better calibration. The diagonal dashed line represents perfect calibration. Smaller gaps between predicted confidence and actual accuracy indicate better calibration. DS fusion reduces calibration error by explicitly modeling uncertainty}{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7}Conflict Analysis}{10}{subsection.5.7}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Conflict Measure Analysis}}{10}{table.caption.9}\protected@file@percent }
\newlabel{tab:conflict}{{2}{10}{Conflict Measure Analysis}{table.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.8}Confusion Matrix Analysis}{10}{subsection.5.8}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Ablation study results: (a) Effect of ensemble size showing performance gains up to 5 models with diminishing returns, (b) Impact of temperature parameter with optimal range 1.0-1.5, (c) Comparison of belief assignment strategies with direct assignment performing best, (d) Importance of model diversity with heterogeneous architectures significantly outperforming homogeneous ensembles.}}{11}{figure.caption.8}\protected@file@percent }
\newlabel{fig:ablation}{{6}{11}{Ablation study results: (a) Effect of ensemble size showing performance gains up to 5 models with diminishing returns, (b) Impact of temperature parameter with optimal range 1.0-1.5, (c) Comparison of belief assignment strategies with direct assignment performing best, (d) Importance of model diversity with heterogeneous architectures significantly outperforming homogeneous ensembles}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.9}Computational Efficiency}{11}{subsection.5.9}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Computational Cost Comparison (per sample)}}{11}{table.caption.11}\protected@file@percent }
\newlabel{tab:computational}{{3}{11}{Computational Cost Comparison (per sample)}{table.caption.11}{}}
\citation{goodfellow2014explaining}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Confusion matrices comparing (a) simple average ensemble and (b) DS fusion ensemble on CIFAR-10 test set. Darker colors on the diagonal indicate higher accuracy. DS fusion shows improved diagonal dominance, particularly for challenging classes like cat, dog, and bird, demonstrating better discrimination between visually similar categories.}}{12}{figure.caption.10}\protected@file@percent }
\newlabel{fig:confusion}{{7}{12}{Confusion matrices comparing (a) simple average ensemble and (b) DS fusion ensemble on CIFAR-10 test set. Darker colors on the diagonal indicate higher accuracy. DS fusion shows improved diagonal dominance, particularly for challenging classes like cat, dog, and bird, demonstrating better discrimination between visually similar categories}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.10}Out-of-Distribution Detection}{12}{subsection.5.10}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Out-of-distribution detection results: (Left) Distribution of conflict measures for in-distribution (CIFAR-10) vs out-of-distribution (SVHN) samples, showing clear separation. (Right) ROC curve demonstrating strong OOD detection performance (AUROC=0.948), significantly better than random baseline.}}{12}{figure.caption.12}\protected@file@percent }
\newlabel{fig:ood}{{8}{12}{Out-of-distribution detection results: (Left) Distribution of conflict measures for in-distribution (CIFAR-10) vs out-of-distribution (SVHN) samples, showing clear separation. (Right) ROC curve demonstrating strong OOD detection performance (AUROC=0.948), significantly better than random baseline}{figure.caption.12}{}}
\citation{gal2016dropout}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.11}Adversarial Robustness}{13}{subsection.5.11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Adversarial robustness analysis: (Left) Conflict distributions for clean vs FGSM-attacked images showing increased uncertainty under attack. (Center) Uncertainty interval widths increase substantially for adversarial examples. (Right) Summary comparison demonstrating that DS fusion detects adversarial perturbations through elevated uncertainty metrics.}}{13}{figure.caption.13}\protected@file@percent }
\newlabel{fig:adversarial}{{9}{13}{Adversarial robustness analysis: (Left) Conflict distributions for clean vs FGSM-attacked images showing increased uncertainty under attack. (Center) Uncertainty interval widths increase substantially for adversarial examples. (Right) Summary comparison demonstrating that DS fusion detects adversarial perturbations through elevated uncertainty metrics}{figure.caption.13}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Adversarial Robustness Results (FGSM, $\epsilon =0.03$)}}{13}{table.caption.14}\protected@file@percent }
\newlabel{tab:adversarial}{{4}{13}{Adversarial Robustness Results (FGSM, $\epsilon =0.03$)}{table.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.12}Comparison with MC Dropout}{13}{subsection.5.12}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Comparison with MC Dropout Uncertainty}}{13}{table.caption.15}\protected@file@percent }
\newlabel{tab:mc_dropout}{{5}{13}{Comparison with MC Dropout Uncertainty}{table.caption.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion}{13}{section.6}\protected@file@percent }
\newlabel{sec:discussion}{{6}{13}{Discussion}{section.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Summary of Key Findings}{13}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Theoretical and Practical Advantages}{14}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Implications for Safety-Critical Applications}{14}{subsection.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Insights from Ablation Studies}{14}{subsection.6.4}\protected@file@percent }
\citation{arxiv2024feature}
\citation{sensoy2018evidential}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Comparison with Recent Work}{15}{subsection.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}Limitations and Future Directions}{15}{subsection.6.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7}Practical Recommendations}{16}{subsection.6.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{16}{section.7}\protected@file@percent }
\newlabel{sec:conclusion}{{7}{16}{Conclusion}{section.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Main Contributions Revisited}{16}{subsection.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Broader Impact}{16}{subsection.7.2}\protected@file@percent }
\bibstyle{plain}
\bibdata{references}
\bibcite{arxiv2024feature}{1}
\bibcite{basir2007engine}{2}
\bibcite{breiman1996bagging}{3}
\bibcite{dempster1968generalization}{4}
\bibcite{dietterich2000ensemble}{5}
\bibcite{freund1997decision}{6}
\bibcite{gal2016dropout}{7}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Future Research Directions}{17}{subsection.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Concluding Remarks}{17}{subsection.7.4}\protected@file@percent }
\bibcite{goodfellow2014explaining}{8}
\bibcite{guo2017calibration}{9}
\bibcite{he2016deep}{10}
\bibcite{hendrycks2016baseline}{11}
\bibcite{huang2017densely}{12}
\bibcite{kendall2017uncertainties}{13}
\bibcite{kiani2017medical}{14}
\bibcite{krizhevsky2009learning}{15}
\bibcite{krizhevsky2012imagenet}{16}
\bibcite{lakshminarayanan2017simple}{17}
\bibcite{le2002application}{18}
\bibcite{liu2024deep}{19}
\bibcite{mackay1992practical}{20}
\bibcite{sandler2018mobilenetv2}{21}
\bibcite{sensoy2018evidential}{22}
\bibcite{shafer1976mathematical}{23}
\bibcite{simonyan2014very}{24}
\bibcite{smets1994transferable}{25}
\bibcite{wolpert1992stacked}{26}
\bibcite{xu1992methods}{27}
\gdef \@abspage@last{18}

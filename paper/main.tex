\documentclass[11pt,twocolumn]{article}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage[margin=0.75in]{geometry}
\usepackage{epstopdf}
\usepackage{subcaption}

\begin{document}

\title{Adaptive Multi-Model Ensemble Fusion with Dempster-Shafer Theory for Robust Image Classification}

\author{Anonymous Author\\
Department of Computer Science, University\\
City, Country\\
\texttt{email@university.edu}}

\maketitle

\begin{abstract}
Ensemble learning has become the de facto approach for achieving state-of-the-art performance in deep learning, yet traditional fusion methods like averaging and voting fail to explicitly quantify uncertainty or detect conflicts between models. This limitation is particularly problematic for safety-critical applications where understanding \textit{when} a model is uncertain is as important as \textit{what} it predicts. We address this gap by proposing a novel ensemble fusion framework based on Dempster-Shafer (DS) evidence theory that provides principled evidence combination with comprehensive uncertainty quantification. Our approach converts neural network softmax outputs into DS mass functions, combines them using Dempster's rule with explicit conflict detection, and generates predictions with interpretable uncertainty metrics including belief, plausibility, and doubt measures. Through extensive experiments on CIFAR-10 using five diverse CNN architectures (ResNet, VGG, MobileNet, DenseNet), we demonstrate that DS fusion achieves 92.3\% accuracy, outperforming simple averaging (91.5\%) and voting (91.2\%). More importantly, we discover a strong correlation between conflict measures and prediction errors—incorrect predictions exhibit 0.36 higher conflict ($p < 0.001$)—validating DS theory's capability to identify uncertain predictions. With minimal computational overhead (< 1\% of end-to-end latency), our framework provides actionable uncertainty metrics suitable for real-world deployment in safety-critical systems including medical diagnosis, autonomous driving, and security applications.
\end{abstract}

\textbf{Keywords:} Dempster-Shafer theory, evidence theory, ensemble learning, uncertainty quantification, image classification, CIFAR-10, deep learning

\section{Introduction}
\label{sec:introduction}
\input{sections/introduction}

\section{Related Work}
\label{sec:related}
\input{sections/related_work}

\section{Methodology}
\label{sec:methodology}
\input{sections/methodology}

\section{Experimental Setup}
\label{sec:experiments}
\input{sections/experiments}

\section{Results and Analysis}
\label{sec:results}
\input{sections/results}

\section{Discussion}
\label{sec:discussion}
\input{sections/discussion}

\section{Conclusion}
\label{sec:conclusion}
\input{sections/conclusion}

\bibliographystyle{plain}
\bibliography{references}

\end{document}
